<!DOCTYPE html><html lang="en" class="dark"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/569ce4b8f30dc480-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/93f479601ee12b01-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/9b14955158d61548.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-013194c79a4f4649.js"/><script src="/_next/static/chunks/ebe977ba-f33e6a37613402e3.js" async=""></script><script src="/_next/static/chunks/411-e865e4c97e426d4b.js" async=""></script><script src="/_next/static/chunks/main-app-a2d3648bc2e3e824.js" async=""></script><script src="/_next/static/chunks/395-ab24c1eea676b652.js" async=""></script><script src="/_next/static/chunks/84-42539fc15c698436.js" async=""></script><script src="/_next/static/chunks/app/ground-truth-generation/page-2015cb914f66c64c.js" async=""></script><meta name="next-size-adjust" content=""/><title>Create Next App</title><meta name="description" content="Generated by create next app"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_4d318d __variable_ea5f4b antialiased"><main class="flex min-h-screen flex-col items-center p-8 sm:p-24"><h1 class="text-4xl font-bold mb-6 text-center">Ground Truth Tensor Generation</h1><div class="w-full max-w-4xl mb-8"><div class="rounded-xl border bg-card text-card-foreground shadow p-6"><div class="flex flex-col md:flex-row items-center mb-6"><div class="md:w-1/2 p-4"><img alt="Ground Truth Tensor Generation" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="rounded-md" style="color:transparent" src="/images/cats_res.png"/></div><div class="md:w-1/2 p-4"><h2 class="text-2xl font-semibold mb-3">Objective</h2><p class="mb-4">Generate patch-level ground truth tensors from annotated images to simulate the output of a simple RPN.</p><h2 class="text-2xl font-semibold mb-3">Setup</h2><ul class="list-disc pl-5 mb-4"><li>Resize input images to 200x200</li><li>Divide each resized image into a 40×40 grid of 5×5 patches</li></ul></div></div><h2 class="text-2xl font-semibold mb-3">Implementation Details</h2><div class="bg-gray-100 dark:bg-gray-800 p-4 rounded-md mb-6 overflow-auto"><pre class="text-sm">def resize_image_and_boxes(image_path, boxes):
    &quot;&quot;&quot;
    Resizes the input image to TARGET_SIZE x TARGET_SIZE and scales bounding boxes
    already defined in the bottom-left origin (x=col, y=row from bottom).
    &quot;&quot;&quot;
    image = Image.open(image_path).convert(&quot;RGB&quot;)
    original_width, original_height = image.size
    
    # Resize the image to TARGET_SIZE x TARGET_SIZE
    image = image.resize((TARGET_SIZE, TARGET_SIZE))
    
    # Scale the bounding boxes
    resized_boxes = []
    for box in boxes:
        x_center, y_center, width, height = box
        
        # Scale the coordinates and dimensions
        new_x_center = x_center * TARGET_SIZE / original_width
        new_y_center = y_center * TARGET_SIZE / original_height
        new_width = width * TARGET_SIZE / original_width
        new_height = height * TARGET_SIZE / original_height
        
        resized_boxes.append([new_x_center, new_y_center, new_width, new_height])
    
    return image, resized_boxes</pre></div><div class="bg-gray-100 dark:bg-gray-800 p-4 rounded-md mb-6 overflow-auto"><pre class="text-sm">def generate_gt_tensors(boxes):
    &quot;&quot;&quot;
    Generates ground-truth existence and location tensors for a resized image.
    &quot;&quot;&quot;
    # Initialize the existence tensor with shape (grid_height, grid_width, 2)
    # It will hold one-hot encoded values: [1, 0] for object, [0, 1] for background
    existence = np.zeros((GRID_NUMBER, GRID_NUMBER, 2))
    
    # Initialize the location tensor to store box details for positive patches
    location = np.zeros((GRID_NUMBER, GRID_NUMBER, 4))
    
    # Generate the patch grid using bottom-left (0, 0) origin
    grid = compute_patch_grid()
    
    # Set all patches to background by default
    existence[:, :, 1] = 1
    
    # For each patch in the grid
    for i, j, patch_x_center, patch_y_center, patch_w, patch_h in grid:
        # Create a patch box in [x_center, y_center, width, height] format
        patch_box = [patch_x_center, patch_y_center, PATCH_SIZE, PATCH_SIZE]
        
        # Find all overlapping ground truth boxes
        overlapping_boxes = []
        for box in boxes:
            if boxes_overlap(patch_box, box):
                overlapping_boxes.append(box)
        
        # If there are overlapping boxes
        if overlapping_boxes:
            # Mark this patch as containing an object
            existence[j, i, 0] = 1
            existence[j, i, 1] = 0
            
            # Randomly pick one of the overlapping boxes
            import random
            selected_box = random.choice(overlapping_boxes)
            
            # Store the selected box&#x27;s coordinates in the location tensor
            location[j, i] = selected_box
    
    return existence, location</pre></div><h2 class="text-2xl font-semibold mb-3">Process</h2><ol class="list-decimal pl-5 mb-6"><li class="mb-2">Resize the image and its bounding boxes to 200x200</li><li class="mb-2">For each patch:<ul class="list-disc pl-5 mt-1"><li>If any GT box overlaps the patch:<ul class="list-disc pl-5 mt-1"><li>Mark Existence[row, col] = [1, 0]</li><li>Randomly pick one overlapping box and write [x_center, y_center, width, height] into the Location tensor</li></ul></li><li>Otherwise, mark Existence[row, col] = [0, 1]</li></ul></li></ol><h2 class="text-2xl font-semibold mb-3">Output</h2><ul class="list-disc pl-5 mb-6"><li>Existence tensor: (GRID_NUMBER, GRID_NUMBER, 2)</li><li>Location tensor: (GRID_NUMBER, GRID_NUMBER, 4)</li></ul><div class="flex justify-between"><a href="/"><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground h-9 px-4 py-2">Back to Home</button></a><a href="/tensor-decoding"><button class="inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&amp;_svg]:pointer-events-none [&amp;_svg]:size-4 [&amp;_svg]:shrink-0 bg-primary text-primary-foreground shadow hover:bg-primary/90 h-9 px-4 py-2">Next: Tensor Decoding</button></a></div></div></div></main><script src="/_next/static/chunks/webpack-013194c79a4f4649.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[9729,[],\"\"]\n3:I[9829,[],\"\"]\n4:I[9224,[],\"ClientPageRoot\"]\n5:I[8578,[\"395\",\"static/chunks/395-ab24c1eea676b652.js\",\"84\",\"static/chunks/84-42539fc15c698436.js\",\"509\",\"static/chunks/app/ground-truth-generation/page-2015cb914f66c64c.js\"],\"default\"]\n8:I[5358,[],\"OutletBoundary\"]\na:I[5358,[],\"MetadataBoundary\"]\nc:I[5358,[],\"ViewportBoundary\"]\ne:I[672,[],\"\"]\n:HL[\"/_next/static/media/569ce4b8f30dc480-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/93f479601ee12b01-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/9b14955158d61548.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"UWgL685_DnIc7gZtM0i8y\",\"p\":\"\",\"c\":[\"\",\"ground-truth-generation\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"ground-truth-generation\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/9b14955158d61548.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"dark\",\"children\":[\"$\",\"body\",null,{\"className\":\"__variable_4d318d __variable_ea5f4b antialiased\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]]}],{\"children\":[\"ground-truth-generation\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"ground-truth-generation\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L4\",null,{\"Component\":\"$5\",\"searchParams\":{},\"params\":{},\"promises\":[\"$@6\",\"$@7\"]}],null,[\"$\",\"$L8\",null,{\"children\":\"$L9\"}]]}],{},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"h1QAsC9VX9JSzUPgKiF74\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n7:{}\n"])</script><script>self.__next_f.push([1,"d:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\nb:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Create Next App\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"Generated by create next app\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"9:null\n"])</script></body></html>